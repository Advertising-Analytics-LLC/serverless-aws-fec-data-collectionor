{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"docs Documentation for serverless-advancedanalytics-fec-data-collection About Docs for serverless functions, including: data-flow diagrams and ERDs development steps for engineers monitoring and remediations for ops misc links. serverless is new, we're all learning Data See the Data docs for data-flow and entity-relationship diagrams. Engineers See the Engineers docs for how to develop Operations See the Operations docs for how to maintain References Resources I referenced when making design decisions are in References","title":"Home"},{"location":"#docs","text":"Documentation for serverless-advancedanalytics-fec-data-collection","title":"docs"},{"location":"#about","text":"Docs for serverless functions, including: data-flow diagrams and ERDs development steps for engineers monitoring and remediations for ops misc links. serverless is new, we're all learning","title":"About"},{"location":"#data","text":"See the Data docs for data-flow and entity-relationship diagrams.","title":"Data"},{"location":"#engineers","text":"See the Engineers docs for how to develop","title":"Engineers"},{"location":"#operations","text":"See the Operations docs for how to maintain","title":"Operations"},{"location":"#references","text":"Resources I referenced when making design decisions are in References","title":"References"},{"location":"DATA/","text":"Data Data Flow The data-flow diagram below shows events, lambdas, queues, and RDS tables. Most data originates with the FEC API but also uses fecfile to parse FEC filings from https://docquery.fec.gov/paper/posted/{fec_file_id}.fec . You can also view the lambdas, along with monitoring and logging, through the aws console ./ Data-Flow Diagram Data Model The tables came from: - The FEC API - candidate_detail -> CandidateDetail from https://api.open.fec.gov/developers/#/candidate/get_candidate__candidate_id__ - committee_detail -> CommitteeDetail from https://api.open.fec.gov/developers/#/committee/get_committee__committee_id__ - committee_candidates -> CommitteeDetail - The docquery filings - filings - filings_amendment_chain - filings_schedule_b - filings_schedule_e - form_1_supplemental - committee_totals If you inspect the data-flow-diagram above you can see what API was used to make any redshift table. Each API endpoint returns a different Data Model. The APIs and their DMs are listed above. The docquery API returns fec files which are pretty free-form Entity Relationship Diagarm This was generated using DataGrip and makes uses of the foreign keys which are not enforced by redshift Database Statistics There is an extra lambda, GetDBStats , that queries the database for row counts and the like. It then writes this information back to the DB with a date for point-in-time records. The lambda code is in src/get_db_stats.py and you can query for it's results from the database with select * from fec.loading_stats; to get something like this: query_time candidate_detail_count candidate_detail_min_first_file committee_detail_count committee_detail_min_first_file filings_count filings_min_receipt_date committee_totals_count filing_amendment_chain_count filings_schedule_b_count filings_schedule_e_count form_1_supplemental_count 2020-08-21 15:40:48.731069 1166 2016-11-06 880 1972-06-09 11454 2019-01-20 897 0 18600 1951 0 2020-08-21 15:42:21.751421 1166 2016-11-06 880 1972-06-09 11454 2019-01-20 897 0 18600 1951 0","title":"Data"},{"location":"DATA/#data","text":"","title":"Data"},{"location":"DATA/#data-flow","text":"The data-flow diagram below shows events, lambdas, queues, and RDS tables. Most data originates with the FEC API but also uses fecfile to parse FEC filings from https://docquery.fec.gov/paper/posted/{fec_file_id}.fec . You can also view the lambdas, along with monitoring and logging, through the aws console ./","title":"Data Flow"},{"location":"DATA/#data-flow-diagram","text":"","title":"Data-Flow Diagram"},{"location":"DATA/#data-model","text":"The tables came from: - The FEC API - candidate_detail -> CandidateDetail from https://api.open.fec.gov/developers/#/candidate/get_candidate__candidate_id__ - committee_detail -> CommitteeDetail from https://api.open.fec.gov/developers/#/committee/get_committee__committee_id__ - committee_candidates -> CommitteeDetail - The docquery filings - filings - filings_amendment_chain - filings_schedule_b - filings_schedule_e - form_1_supplemental - committee_totals If you inspect the data-flow-diagram above you can see what API was used to make any redshift table. Each API endpoint returns a different Data Model. The APIs and their DMs are listed above. The docquery API returns fec files which are pretty free-form","title":"Data Model"},{"location":"DATA/#entity-relationship-diagarm","text":"This was generated using DataGrip and makes uses of the foreign keys which are not enforced by redshift","title":"Entity Relationship Diagarm"},{"location":"DATA/#database-statistics","text":"There is an extra lambda, GetDBStats , that queries the database for row counts and the like. It then writes this information back to the DB with a date for point-in-time records. The lambda code is in src/get_db_stats.py and you can query for it's results from the database with select * from fec.loading_stats; to get something like this: query_time candidate_detail_count candidate_detail_min_first_file committee_detail_count committee_detail_min_first_file filings_count filings_min_receipt_date committee_totals_count filing_amendment_chain_count filings_schedule_b_count filings_schedule_e_count form_1_supplemental_count 2020-08-21 15:40:48.731069 1166 2016-11-06 880 1972-06-09 11454 2019-01-20 897 0 18600 1951 0 2020-08-21 15:42:21.751421 1166 2016-11-06 880 1972-06-09 11454 2019-01-20 897 0 18600 1951 0","title":"Database Statistics"},{"location":"ENG/","text":"Engineering Getting started These instructions are for engineers wishing to develop the project. 0. Install prerequisites Make sure python , npm , and the aws cli are installed. The services are written in python and serverless is an npm package. They are deployed to AWS. 1. Install development packages These requirements can be installed with bin/dev-setup.sh . This script installs serverless and creates a local python virtualenv for developing the functions. See bin/dev-setup.sh . 2. Develop Edit the code and run locally with sls invoke local -f hello . Replace hello with the name of your function. 3. Deploy First you will need to log into AWS through the cli. Then you can deploy your function with sls deploy . Happy coding! Testing This project uses pytest for testing. To run the tests you need the environmental variables in your shell and you will need to be logged into aws. Once you've done that you can run pytest . This will call the services as they exist in AWS. You can also enable log output during tests by adding log_cli = True to pytest.ini .","title":"Eng"},{"location":"ENG/#engineering","text":"","title":"Engineering"},{"location":"ENG/#getting-started","text":"These instructions are for engineers wishing to develop the project.","title":"Getting started"},{"location":"ENG/#0-install-prerequisites","text":"Make sure python , npm , and the aws cli are installed. The services are written in python and serverless is an npm package. They are deployed to AWS.","title":"0. Install prerequisites"},{"location":"ENG/#1-install-development-packages","text":"These requirements can be installed with bin/dev-setup.sh . This script installs serverless and creates a local python virtualenv for developing the functions. See bin/dev-setup.sh .","title":"1. Install development packages"},{"location":"ENG/#2-develop","text":"Edit the code and run locally with sls invoke local -f hello . Replace hello with the name of your function.","title":"2. Develop"},{"location":"ENG/#3-deploy","text":"First you will need to log into AWS through the cli. Then you can deploy your function with sls deploy . Happy coding!","title":"3. Deploy"},{"location":"ENG/#testing","text":"This project uses pytest for testing. To run the tests you need the environmental variables in your shell and you will need to be logged into aws. Once you've done that you can run pytest . This will call the services as they exist in AWS. You can also enable log output during tests by adding log_cli = True to pytest.ini .","title":"Testing"},{"location":"OPS/","text":"Operations Guide for maintaining this project Monitoring Metrics like invocations, errors, and duration are available on the AWS Lambda App Console . Logging CloudWatch Logs are available for all the functions. The logs can be viewed from the Lambda App Console The LOG_LEVEL is set in serverless.yml and controls the verbosity of the logs.","title":"Ops"},{"location":"OPS/#operations","text":"Guide for maintaining this project","title":"Operations"},{"location":"OPS/#monitoring","text":"Metrics like invocations, errors, and duration are available on the AWS Lambda App Console .","title":"Monitoring"},{"location":"OPS/#logging","text":"CloudWatch Logs are available for all the functions. The logs can be viewed from the Lambda App Console The LOG_LEVEL is set in serverless.yml and controls the verbosity of the logs.","title":"Logging"},{"location":"REFS/","text":"References the AWS serverless.yml reference this serverless/examples example FEC API docs","title":"References"},{"location":"REFS/#references","text":"the AWS serverless.yml reference this serverless/examples example FEC API docs","title":"References"}]}